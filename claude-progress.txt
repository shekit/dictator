# Dictator - Progress Log

This file tracks progress across coding sessions. Append new entries at the bottom.

---

## Session 0 - 2026-01-20 (Setup)
- Created harness system
- Created CLAUDE.md (agent instructions)
- Created ARCHITECTURE.md (project overview)
- Created features.json (9 phases, 54 features)
- Created init.sh (dev environment setup)
- Created this progress file

### Current State
- Harness system ready
- No code written yet
- Next: Phase 1, Feature 1.1 (Create Swift package)

---

## Session 1 - 2026-01-20 (Phase 1 Complete)
- Implemented all Phase 1 features (1.1 - 1.4)
- Created Swift package structure in Dictator/
- Created DictatorApp.swift (main entry point with SwiftUI App)
- Created AppDelegate.swift (app lifecycle management)
- Created StatusBarController.swift (menu bar icon and menu)
- Created Info.plist with LSUIElement=true (no Dock icon)
- Created build-app.sh script for packaging .app bundle

### Files Created
- Dictator/Package.swift
- Dictator/Sources/Dictator/App/DictatorApp.swift
- Dictator/Sources/Dictator/App/AppDelegate.swift
- Dictator/Sources/Dictator/UI/StatusBarController.swift
- Dictator/Sources/Dictator/Info.plist
- Dictator/build-app.sh

### Verification
- `swift build` succeeds without errors
- App bundle created at Dictator/Dictator.app
- Menu bar icon uses SF Symbol "mic.fill"
- Quit menu item terminates app
- LSUIElement configured (no Dock icon)

### Current State
- Phase 1 complete (4/4 features passing)
- Next: Phase 2, Feature 2.1 (Global hotkey registration)

---

## Session 2 - 2026-01-20 (Phase 2 Complete)
- Implemented all Phase 2 features (2.1 - 2.7)
- Created GlobalHotkeyManager for Ctrl+Option+Space detection using CGEvent tap
- Created AudioRecorder with AVAudioEngine for microphone capture
- Created RecordingService to coordinate hotkey + audio
- Updated StatusBarController with visual indicators

### Files Created
- Dictator/Sources/Dictator/Audio/GlobalHotkeyManager.swift
- Dictator/Sources/Dictator/Audio/AudioRecorder.swift
- Dictator/Sources/Dictator/Audio/RecordingService.swift

### Files Modified
- Dictator/Sources/Dictator/UI/StatusBarController.swift (added recording state icons)
- Dictator/Sources/Dictator/App/AppDelegate.swift (integrated RecordingService)

### Implementation Details
- CGEvent tap with health monitoring (re-enables if disabled by macOS)
- Thread-safe audio buffer with NSLock for concurrent access
- AVAudioEngine stored as AnyObject to avoid Combine reflection crashes
- Delayed initialization (1.5s) to avoid race conditions at launch
- Menu bar icon changes: mic.fill (idle) -> mic.circle.fill (recording) -> mic.slash.fill (error)
- Accessibility permission prompt via AXIsProcessTrustedWithOptions
- Microphone permission handling with helpful error messages

### Post-Implementation Updates
- Changed hotkey from Ctrl+Option+Space to **fn key** (hold to record)
- Added cancel behavior: fn + other key cancels recording (allows F1-F12 to work)
- Fixed permission handling:
  - Added permission polling timer to auto-detect when permission is granted
  - Removed NSAlert that was interfering with permission detection
  - App must be launched via `open ./Dictator.app` to properly gain permissions

### Verification
- `swift build` succeeds without errors
- App bundle created at Dictator/Dictator.app
- Hotkey: fn key (hold to record, release to stop, fn+other key cancels)
- Console logs show hotkey events and buffer sizes
- Menu bar icon changes during recording
- Graceful error handling for missing permissions

### Current State
- Phase 2 complete (7/7 features passing)
- Next: Phase 3, Feature 3.1 (Add FluidAudio dependency)

---

## Session 3 - 2026-01-20 (Phase 3 Complete)
- Implemented all Phase 3 features (3.1 - 3.6)
- Integrated FluidAudio library for speech-to-text transcription
- Created TranscriptionService to wrap AsrManager with proper serialization
- Updated RecordingService to transcribe audio after recording stops
- Added transcribing state and visual indicator to UI

### Files Created
- Dictator/Sources/Dictator/STT/TranscriptionService.swift

### Files Modified
- Dictator/Package.swift (added FluidAudio dependency from GitHub)
- Dictator/Sources/Dictator/Audio/RecordingService.swift (added transcription flow)
- Dictator/Sources/Dictator/UI/StatusBarController.swift (added transcribing state)
- Dictator/Sources/Dictator/App/AppDelegate.swift (model preloading, transcription callback)

### Implementation Details
- FluidAudio dependency: `https://github.com/FluidInference/FluidAudio` version 0.10.0
- Uses Parakeet TDT v2 model (~450MB) - downloads automatically on first run
- Models stored in `~/Library/Application Support/FluidAudio/Models/`
- TranscriptionExecutor actor serializes FluidAudio calls (CoreML requirement)
- Empty recording handling: rejects audio < 100ms (1600 samples at 16kHz)
- Menu bar icon: waveform.circle.fill during transcription
- Lazy model loading: starts in background at launch, ready for first transcription

### Verification
- `swift build` succeeds without errors
- `swift package resolve` fetches FluidAudio successfully
- Model files download to Application Support on first run
- App handles empty/silent recordings gracefully
- Menu bar shows transcribing state during processing

### Current State
- Phase 3 complete (6/6 features passing)
- Next: Phase 4, Feature 4.1 (Request Accessibility permission)

---

## Session 4 - 2026-01-20 (Phase 4 Complete)
- Implemented all Phase 4 features (4.1 - 4.6)
- Created TextInjectionService for clipboard-based text injection
- Full end-to-end flow now works: hold fn → speak → release → transcribe → inject text at cursor

### Files Created
- Dictator/Sources/Dictator/Injection/TextInjectionService.swift

### Files Modified
- Dictator/Sources/Dictator/Audio/RecordingService.swift (added injecting state, text injection call)
- Dictator/Sources/Dictator/UI/StatusBarController.swift (added injecting state UI)

### Implementation Details
- TextInjectionService uses singleton pattern (shared instance)
- Clipboard operations:
  1. saveClipboard() - stores all NSPasteboardItem data
  2. writeToClipboard() - writes transcription text
  3. restoreClipboard() - restores original clipboard contents
- Keystroke simulation uses CGEvent for Cmd+V
- Timing: 50ms delay before paste, 100ms delay before restore
- Accessibility permission check with helpful prompt and settings link
- Menu bar icon shows "text.cursor" SF Symbol during injection
- RecordingService.State now includes .injecting state

### Verification
- `swift build` succeeds without errors
- App bundle created at Dictator/Dictator.app
- Accessibility permission requested when needed
- Clipboard contents preserved and restored after injection
- Text appears at cursor position after speaking
- Full workflow: fn (hold) → speak → fn (release) → transcription → injection

### Current State
- Phase 4 complete (6/6 features passing)
- Next: Phase 5, Feature 5.1 (OpenRouter API client)

---

## Session 5 - 2026-01-20 (Phase 5 Complete)
- Implemented all Phase 5 features (5.1 - 5.9)
- Created OpenRouter API client for cloud LLM processing
- Created EnvLoader for .env file configuration
- Created LLMService with prompt system (main, advanced, dictionary)
- Added model selection and LLM toggle to menu bar

### Files Created
- Dictator/Sources/Dictator/Storage/EnvLoader.swift
- Dictator/Sources/Dictator/LLM/OpenRouterClient.swift
- Dictator/Sources/Dictator/LLM/LLMService.swift

### Files Modified
- Dictator/Sources/Dictator/Audio/RecordingService.swift (added LLM processing step)
- Dictator/Sources/Dictator/UI/StatusBarController.swift (added LLM toggle, model selection)
- Dictator/Sources/Dictator/App/AppDelegate.swift (EnvLoader initialization)

### Implementation Details
- EnvLoader reads .env from: app bundle dir, ~/.env, or ~/Documents/Dictator/.env
- OpenRouterClient with retry logic, rate limiting, and error handling
- 8 cloud models available: Groq Llama, Claude, GPT-4o, Gemini, Mistral
- LLMService.ProcessingMode: .cloud, .local (Phase 6), .off
- Main prompt removes fillers (um, uh, like, you know) and adds punctuation
- Advanced prompt (toggleable) handles backtracking/corrections
- Dictionary entries allow custom term replacements
- All settings persist via UserDefaults
- Graceful fallback to raw transcription on API errors

### Menu Bar Changes
- "LLM: Cloud: Llama 3.1 70B" status display
- "Enable/Disable LLM Processing" toggle
- "Cloud Model" submenu with checkmarked selection

### Verification
- `swift build` succeeds without errors
- App bundle created at Dictator/Dictator.app
- .env file loaded correctly at startup
- OpenRouter API calls work with valid key
- Model selection persists across restarts
- Toggle state persists across restarts
- Falls back to raw text on API error

### Current State
- Phase 5 complete (9/9 features passing)
- Next: Phase 6, Feature 6.1 (Check if Ollama is running)

---

